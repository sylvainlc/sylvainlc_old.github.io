<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data sciences at TSP on Sylvain Le Corff</title>
    <link>/project/</link>
    <description>Recent content in Data sciences at TSP on Sylvain Le Corff</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sun, 01 Jan 2017 00:00:00 +0100</lastBuildDate>
    
	<atom:link href="/project/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Algorithms &amp; Simulations</title>
      <link>/project/algorithms/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0200</pubDate>
      
      <guid>/project/algorithms/</guid>
      <description>Shrinkage-thresholding MALA for Bayesian variable selection
Bayesian variable selection algorithm based on the paper Schreck et al. (arXiv:1312.5658). The method is based on the combination of a Metropolis Adjusted Langevin Algorithm (MALA) step with a shrinkage-thresholding operator. The algorithm is compared to the Reversible jump MCMC algorithm, see Green (95-BIOMET:711): ees_C.tar.gz &amp;copy;, stmala_C.tar.gz (Matlab)

Online parameter estimation for a Stochastic Volatility model
The parameters are estimated with the Block Online EM algorithm, see Le Corff and Fort (2013) (13-EJS:789 and ACM-Tomacs): OnlineEM_SVM.</description>
    </item>
    
    <item>
      <title>Data sciences @TSP</title>
      <link>/project/datasciences/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0200</pubDate>
      
      <guid>/project/datasciences/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Data sciences working groups</title>
      <link>/project/datascienceswg/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0200</pubDate>
      
      <guid>/project/datascienceswg/</guid>
      <description>Session 1: From machine learning basics to Feed Forward Neural Networks
Session 2: Optimization for machine/deep learning</description>
    </item>
    
    <item>
      <title>Students</title>
      <link>/project/students/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0200</pubDate>
      
      <guid>/project/students/</guid>
      <description>Ph.D. sutdents 
Alice Martin (Telecom SudParis &amp;amp; Ecole Polytechnique, 2019 - &amp;hellip;)
Co-supervised with Olivier Pietquin (Google Brain)
Deep reinforcement learning for natural language processing. Application to goal-oriented visual question generation
Thi Ngoc Minh Nguyen (Telecom ParisTech &amp;amp; Lunalogic, 2015 - 2016)
Co-supervised with Eric Moulines (Ecole Polytechnique)
Smoothing of linear Gaussian models with Markov regime. Applications to commodity market models
06-18 - &amp;hellip; Quantitative Porfolio Manager at Q-Hedge Technologies</description>
    </item>
    
    <item>
      <title>Teaching materials (Machine Learning, Statistics)</title>
      <link>/project/teaching/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0200</pubDate>
      
      <guid>/project/teaching/</guid>
      <description>Introduction to computational statistics, machine learning and deep learning
Dimension reduction (SVD, PCA, use before machine learning algorithms) PCA (Python ipynb).
Introduction to machine learning (random forest, gradient descent, feed forward neural networks) Intro to machine learning (Python ipynb).
Machine learning algorithms for the Ms. Sc. Advanced Machine learning (3rd year) @Ecole Polytechnique
AdaBoost and Random forests pdf.
Kernel Principal Component Analysis pdf.
Kmeans and Expectation Maximization algorithms pdf.
Machine learning algorithms for the Ms.</description>
    </item>
    
  </channel>
</rss>