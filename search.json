[{"authors":["Sylvain Le Corff"],"categories":["Call for proposals"],"date":1545177600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545177600,"objectID":"06c209f5220e4d2777a73a43ef9824f1","permalink":"/datasciencesattsp/12_19_dga_ia/","publishdate":"2018-12-19T00:00:00Z","relpermalink":"/datasciencesattsp/12_19_dga_ia/","section":"datasciencesattsp","summary":"DGA call about AI oriented procedures for mid-term defense applications.  General presentation of the call DGA call for IA   Four main topics Fusion, correlation, detection of weak signals in high dimension,  detection in low signal to noise ratio settings, defensive cyber warfare and Autonomous mobile robotics.   Deadline 8 of January 2019 at 5p.m. ","tags":[],"title":"DGA call: IA","type":"datasciencesattsp"},{"authors":["Sylvain Le Corff"],"categories":["Thematique phare IMT"],"date":1545091200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545091200,"objectID":"b8275bdc56ef5fa1f35e5da4a986264e","permalink":"/datasciencesattsp/12_18_h2020/","publishdate":"2018-12-18T00:00:00Z","relpermalink":"/datasciencesattsp/12_18_h2020/","section":"datasciencesattsp","summary":"General presentation of the calls H2020 in early 2019 related to Big Data, Data sciences and Artificial intelligence.  A general presentation by Pierre Simay, Isabelle de Sutter and Julia Morawski: H2020 calls.   Other presentations by companies \u0026 teams involved in data sciences projects relevant for these calls. If you are interested in some of these projects/calls or if you are already involved in a process for one of these H2020 calls please contact me at sylvain.","tags":[],"title":"H2020 calls: Big Data \u0026 IA","type":"datasciencesattsp"},{"authors":["Sylvain Le Corff"],"categories":["Thematique phare IMT"],"date":1545091200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545091200,"objectID":"1dc589bf43e5cf742ffa3f57962a0fd2","permalink":"/datasciencesattsp/12_18_carto/","publishdate":"2018-12-18T00:00:00Z","relpermalink":"/datasciencesattsp/12_18_carto/","section":"datasciencesattsp","summary":"Overview of data sciences at Telecom SudParis for the IMT Thematique phare \"Intelligence artificielle et sciences des donnees\". This file gathers projects led in SAMOVAR and the associated researchers which set the focus on problems related to data sciences. DataIA_TSP_AAAI ","tags":[],"title":"Overview of data sciences at Telecom SudParis","type":"datasciencesattsp"},{"authors":["Le Corff, S.","Lerasle, M.","Vernet, E."],"categories":null,"date":1533074400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1533074400,"objectID":"fa08a344b765eaa536fd83dfe888ed32","permalink":"/publication/lecorff_lerasle_vernet_2018/","publishdate":"2018-08-01T00:00:00+02:00","relpermalink":"/publication/lecorff_lerasle_vernet_2018/","section":"publication","summary":"This paper deals with the estimation of the unknown distribution of hidden random variables from the observation of pairwise comparisons between these variables. This problem is inspired by recent developments on Bradley-Terry models in random environment since this framework happens to be relevant to predict for instance the issue of a championship from the observation of a few contests per team. This paper provides three contributions on a Bayesian nonparametric approach to solve this problem. First, we establish contraction rates of the posterior distribution. We also propose a Markov Chain Monte Carlo  algorithm to approximately sample from this posterior distribution inspired from a recent Bayesian nonparametric method for hidden Markov models. Finally, the performance of this algorithm are appreciated by comparing predictions on the issue of a championship based on the actual values of the teams and those obtained by sampling from the estimated posterior distribution.","tags":[],"title":"A Bayesian nonparametric approach for generalized Bradley-Terry models in random environment","type":"publication"},{"authors":null,"categories":null,"date":1530136800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530136800,"objectID":"18d05a63a1c8d7ed973cc51838494e41","permalink":"/privacy/","publishdate":"2018-06-28T00:00:00+02:00","relpermalink":"/privacy/","section":"","summary":"\u0026hellip;","tags":null,"title":"Privacy Policy","type":"page"},{"authors":["Le Corff, S.","Champagne, A.","Charbit, M.","Noziere, G.","Moulines, E"],"categories":null,"date":1527804000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527804000,"objectID":"290ab4154df5e26505fa845a8401b669","permalink":"/publication/lecorff_charbit_champagne_noziere_moulines_2018/","publishdate":"2018-06-01T00:00:00+02:00","relpermalink":"/publication/lecorff_charbit_champagne_noziere_moulines_2018/","section":"publication","summary":"","tags":[],"title":"Optimizing thermal comfort and energy consumption in a large building without renovation work","type":"publication"},{"authors":["Gloaguen, P.","Etienne, M.-P.","Le Corff, S."],"categories":null,"date":1522533600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1522533600,"objectID":"5d837697fca0a791ab0bcb5996290998","permalink":"/publication/gloaguen_etienne_lecorff_2018/","publishdate":"2018-04-01T00:00:00+02:00","relpermalink":"/publication/gloaguen_etienne_lecorff_2018/","section":"publication","summary":"This paper proposes a new model for individuals movement in ecology. The movement process is defined as a solution to a stochastic differential equation whose drift is the gradient of a multimodal potential surface. This offers a new flexible approach among the popular potential based movement models in ecology. To perform parameter inference, the widely used Euler method is compared with two other pseudo-likelihood procedures and  with  a Monte Carlo Expectation Maximization approach based on exact simulation of diffusions . Performances of all methods are assessed with simulated data and with a data set of fishing vessels trajectories. We show that the usual Euler method performs worse than the other procedures for all sampling schemes.","tags":[],"title":"Stochastic differential equation based on a multimodal potential to model movement data in ecology","type":"publication"},{"authors":["NGuyen, T.N.M.","Le Corff, S.","Moulines, E."],"categories":null,"date":1519858800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1519858800,"objectID":"237943b649b14550c0cc6ba678d2fcba","permalink":"/publication/nguyen_lecorff_moulines_2018/","publishdate":"2018-03-01T00:00:00+01:00","relpermalink":"/publication/nguyen_lecorff_moulines_2018/","section":"publication","summary":"A prevalent problem in general state-space models is the approximation of the smoothing distribution of a state conditional on the observations from the past, the present, and the future. The aim of this paper is to provide a rigorous analysis of such approximations of smoothed distributions provided by the two-filter algorithms. We extend the results available for the approximation of smoothing distributions to these two-filter approaches which combine a forward filter approximating the filtering distributions with a backward information filter approximating a quantity proportional to the posterior distribution of the state, given future observations.","tags":[],"title":"On the two-filter approximations of marginal smoothing distributions in general state space models","type":"publication"},{"authors":["Gloaguen, P.","Etienne, M.-P.","Le Corff, S."],"categories":null,"date":1517439600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1517439600,"objectID":"7e212558d7ef644a65f76db7126b859f","permalink":"/publication/gloaguen_etienne_lecorff_2018b/","publishdate":"2018-02-01T00:00:00+01:00","relpermalink":"/publication/gloaguen_etienne_lecorff_2018b/","section":"publication","summary":"This paper introduces a new algorithm to approximate smoothed additive functionals of partially observed diffusion processes. This method relies on a new sequential Monte Carlo method which allows to compute such approximations online, i.e., as the observations are received, and with a computational complexity growing linearly with the number of Monte Carlo samples. The original algorithm cannot be used in the case of partially observed stochastic differential equations since the transition density of the latent data is usually unknown. We prove that it may be extended to partially observed continuous processes by replacing this unknown quantity by an unbiased estimator obtained for instance using general Poisson estimators. This estimator is proved to be consistent and its performance are illustrated using data from two models.","tags":[],"title":"Online sequential Monte Carlo smoother for partially observed diffusion processes","type":"publication"},{"authors":["Diel, R.","Le Corff, S.","Lerasle, M."],"categories":null,"date":1514761200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514761200,"objectID":"e6adc7c54f83a59d396a484e616f6265","permalink":"/publication/diel_lecorff_lerasle_2018/","publishdate":"2018-01-01T00:00:00+01:00","relpermalink":"/publication/diel_lecorff_lerasle_2018/","section":"publication","summary":"In this paper, we consider a tournament where a large number N of players face each others by pairs according to the round-robin scheduling. The dataset is a collection of results of these contests after n rounds, with a special attention to the case where N is much larger than n. Each player is represented by a random strength and the strengths are supposed to be i.i.d. The paper studies the maximum likelihood estimator of the competitors strength distribution. The analysis relies on the construction of a graphical model encoding conditional dependencies of the observations, that is the outcomes of the first n rounds.  This graphical model allows to prove geometric loss of memory properties and deduce the asymptotic behavior of the likelihood function. Following a classical construction in learning theory, the asymptotic likelihood is used to define a measure of performance for the maximum likelihood estimator. Risk bounds for this estimator are finally obtained by sub-Gaussian deviation results for Markov chains applied to our graphical model.","tags":[],"title":"Learning the distribution of latent variables in paired comparison models","type":"publication"},{"authors":["Durmus, A.","Le Corff, S.","Moulines, E.","Roberts, G.O."],"categories":null,"date":1512082800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512082800,"objectID":"a4a4d1090651b4973f7dd2ab3253315a","permalink":"/publication/durmus_lecorff_moulines_roberts_2017/","publishdate":"2017-12-01T00:00:00+01:00","relpermalink":"/publication/durmus_lecorff_moulines_roberts_2017/","section":"publication","summary":"In this paper we consider the optimal scaling of high-dimensional random walk Metropolis algorithms for densities differentiable in the Lp mean but which may be irregular at some points (such as the Laplace density, for example) and/or supported on an interval. Our main result is the weak convergence of the Markov chain (appropriately rescaled in time and space) to a Langevin diffusion process as the dimension d goes to infinity. As the log-density might be nondifferentiable, the limiting diffusion could be singular. The scaling limit is established under assumptions which are much weaker than the one used in the original derivation of Roberts et al. (1997). This result has important practical implications for the use of random walk Metropolis algorithms in Bayesian frameworks based on sparsity inducing priors.","tags":[],"title":"Optimal scaling of the Random Walk Metropolis algorithm under Lp mean differentiability","type":"publication"},{"authors":["NGuyen, T.N.M.","Le Corff, S.","Moulines, E."],"categories":null,"date":1512082800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512082800,"objectID":"a114ca1f192a35142bd2e701717887e8","permalink":"/publication/nguyen_lecorff_moulines_2017/","publishdate":"2017-12-01T00:00:00+01:00","relpermalink":"/publication/nguyen_lecorff_moulines_2017/","section":"publication","summary":"This paper focuses on sequential Monte Carlo approximations of smoothing distributions in conditionally linear and Gaussian state spaces. To reduce Monte Carlo variance of smoothers, it is typical in these models to use Rao-Blackwellization: particle approximation is used to sample sequences of hidden regimes while the Gaussian states are explicitly integrated conditional on the sequence of regimes and observations, using variants of the Kalman filter/smoother. The first successful attempt to use Rao-Blackwellization for smoothing extends the Bryson-Frazier smoother for Gaussian linear state space models using the generalized two-filter formula together with Kalman filters/smoothers. More recently, a forward-backward decomposition of smoothing distributions mimicking the Rauch-Tung-Striebel smoother for the regimes combined with backward Kalman updates has been introduced. This paper investigates the benefit of introducing additional rejuvenation steps in all these algorithms to sample at each time instant new regimes conditional on the forward and backward particles. This defines particle-based approximations of the smoothing distributions whose support is not restricted to the set of particles sampled in the forward or backward filter. These procedures are applied to commodity markets which are described using a two-factor model based on the spot price and a convenience yield for crude oil data.","tags":[],"title":"Particle rejuvenation of Rao-Blackwellized Sequential Monte Carlo smoothers for Conditionally Linear and Gaussian models","type":"publication"},{"authors":["de Castro, Y.","Gassiat, E.","Le Corff, S."],"categories":null,"date":1504216800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1504216800,"objectID":"b77129d399197010db34a302105348a2","permalink":"/publication/decastro_gassiat_lecorff_2017/","publishdate":"2017-09-01T00:00:00+02:00","relpermalink":"/publication/decastro_gassiat_lecorff_2017/","section":"publication","summary":"In this paper, we consider the filtering and smoothing recursions in nonparametric finite state space hidden Markov models (HMMs) when the parameters of the model are unknown and replaced by estimators. We provide an explicit and time uniform control of the filtering and smoothing errors in total variation norm as a function of the parameter estimation errors. We prove that the risk for the filtering and smoothing errors may be uniformly upper bounded by the L1-risk of the estimators. It has been proved very recently that statistical inference for finite state space nonparametric HMMs is possible. We study how the recent spectral methods developed in the parametric setting may be extended to the nonparametric framework and we give explicit upper bounds for the L2-risk of the nonparametric spectral estimators. In the case where the observation space is compact, this provides explicit rates for the filtering and smoothing errors in total variation norm. The performance of the spectral method is assessed with simulated data for both the estimation of the (nonparametric) conditional distribution of the observations and the estimation of the marginal smoothing distributions.","tags":[],"title":"Consistent estimation of the filtering and marginal smoothing distributions in nonparametric hidden Markov models","type":"publication"},{"authors":["Dumont, T.","Le Corff, S."],"categories":null,"date":1504216800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1504216800,"objectID":"fdb3e9c92d0ffd11d1628559ef8a5737","permalink":"/publication/dumont_lecorff_2017/","publishdate":"2017-09-01T00:00:00+02:00","relpermalink":"/publication/dumont_lecorff_2017/","section":"publication","summary":"This paper outlines a new nonparametric estimation procedure for unobserved phi-mixing processes. It is assumed that the only information on the stationary hidden states Xk is given by the process Yk, where Yk is a noisy observation of f(Xk). The paper introduces a maximum pseudo-likelihood procedure to estimate the function f and the distribution vb of the first b states using blocks of observations of length b. The identifiability of the model is studied in the particular cases b = 1 and b = 2 and the consistency of the estimators of f and of vb, as the number of observations grows to infinity is established.","tags":[],"title":"Nonparametric regression on hidden phi-mixing variables: identifiability and consistency of a pseudo-likelihood based estimation procedure","type":"publication"},{"authors":["Dahlhaus, R.","Dumont, T.","Le Corff, S.","Neddermeyer, J.C."],"categories":null,"date":1504216800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1504216800,"objectID":"6a355c5399a291af5f005ee36769dfa3","permalink":"/publication/dahlhaus_dumont_lecorff_neddermeyer_2017/","publishdate":"2017-09-01T00:00:00+02:00","relpermalink":"/publication/dahlhaus_dumont_lecorff_neddermeyer_2017/","section":"publication","summary":"A new model for time series with a specific oscillation pattern is proposed. The model consists of a hidden phase process controlling the speed of polling and a nonparametric curve characterizing the pattern, leading together to a generalized state space model. Identifiability of the model is proved and a method for statistical inference based on a particle smoother and a nonparametric EM algorithm is developed. In particular, the oscillation pattern and the unobserved phase process are estimated. The proposed algorithms are computationally efficient and their performance is assessed through simulations and an application to human electrocardiogram recordings.","tags":[],"title":"Statistical inference for oscillation processes","type":"publication"},{"authors":null,"categories":null,"date":1461708000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461708000,"objectID":"4f8de012cace8a82f7cbb44d46086df5","permalink":"/project/algorithms/","publishdate":"2016-04-27T00:00:00+02:00","relpermalink":"/project/algorithms/","section":"project","summary":"Notebooks, Matlab codes, R Markdown associated with M.Sc. in  Machine learning or with scientific publications","tags":null,"title":"Algorithms","type":"project"},{"authors":null,"categories":null,"date":1461708000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461708000,"objectID":"de2885a70a2ec92d1e60d116ae39dc7a","permalink":"/project/datasciences/","publishdate":"2016-04-27T00:00:00+02:00","relpermalink":"/project/datasciences/","section":"project","summary":"Publications about research activities at TSP related to data sciences and AI (seminars, calls for proposals, etc.)","tags":null,"title":"Data sciences @ TSP","type":"project"},{"authors":null,"categories":null,"date":1461708000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461708000,"objectID":"ec6d9d49261e10091d14dedaaf9d07e6","permalink":"/project/students/","publishdate":"2016-04-27T00:00:00+02:00","relpermalink":"/project/students/","section":"project","summary":"Supervision activities (internships, Ms.Sc., Ph.D., fellowships)","tags":null,"title":"Students","type":"project"},{"authors":["Schreck, A.","Fort, G.","Le Corff, S.","Moulines, E."],"categories":null,"date":1446159600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1446159600,"objectID":"8524547d382dfad89e852d88a6b8b49f","permalink":"/publication/schreck_fort_lecorff_moulines_2015/","publishdate":"2015-10-30T00:00:00+01:00","relpermalink":"/publication/schreck_fort_lecorff_moulines_2015/","section":"publication","summary":"This paper introduces a new Markov Chain Monte Carlo method for Bayesian variable selection in high dimensional settings. The algorithm is a Hastings-Metropolis sampler with a proposal mechanism which combines a Metropolis Adjusted Langevin (MALA) step to propose local moves associated with a shrinkage-thresholding step allowing to propose new models. The geometric ergodicity of this new trans-dimensional Markov Chain Monte Carlo sampler is established. An extensive numerical experiment, on simulated and real data, is presented to illustrate the performance of the proposed algorithm in comparison with some more classical trans-dimensional algorithms.","tags":[],"title":"A shrinkage-thresholding Metropolis adjusted Langevin algorithm for Bayesian variable selection","type":"publication"},{"authors":["Dumont, T.","Le Corff, S."],"categories":null,"date":1409522400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1409522400,"objectID":"0d732c6e03a4f9b270878c5895c7b7ed","permalink":"/publication/dumont_lecorff_2014/","publishdate":"2014-09-01T00:00:00+02:00","relpermalink":"/publication/dumont_lecorff_2014/","section":"publication","summary":"Mobile device localization in wireless sensor networks is a challenging task. It has already been addressed when the WiFi propagation maps of the access points are modeled deterministically or estimated using an offline human training calibration. However, these techniques do not take into account the environmental dynamics. In this paper, the maps are assumed to be made of an average indoor propagation model combined with a perturbation field which represents the influence of the environment. This perturbation field is embedded with a distribution describing the prior knowledge about the environmental influence. The device is localized with Sequential Monte Carlo methods and relies on the estimation of the propagation maps. This inference task is performed online, using the observations sequentially, with a new online Expectation Maximization based algorithm. The performance of the algorithm is illustrated with Monte Carlo experiments using both simulated data and a true data set.","tags":[],"title":"Simultaneous localization and mapping problem in wireless sensor networks","type":"publication"},{"authors":["Le Corff, S.","Fort, G."],"categories":null,"date":1377986400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1377986400,"objectID":"c182e13ff73b544d023f7f9800dfcb05","permalink":"/publication/lecorff_fort_2013b/","publishdate":"2013-09-01T00:00:00+02:00","relpermalink":"/publication/lecorff_fort_2013b/","section":"publication","summary":"Online variants of the Expectation Maximization (EM) algorithm have recently been proposed to perform parameter inference with large data sets or data streams, in independent latent models and in hidden Markov models. Nevertheless, the convergence properties of these algorithms remain an open problem at least in the hidden Markov case. This contribution deals with a new online EM algorithm that updates the parameter at some deterministic times. Some convergence results have been derived even in general latent models such as hidden Markov models. These properties rely on the assumption that some intermediate quantities are available in closed form or can be approximated by Monte Carlo methods when the Monte Carlo error vanishes rapidly enough. In this article, we propose an algorithm that approximates these quantities using Sequential Monte Carlo methods. The convergence of this algorithm and of an averaged version is established and their performance is illustrated through Monte Carlo experiments.","tags":[],"title":"Convergence of a Particle-based Approximation of the Block Online Expectation Maximization Algorithm","type":"publication"},{"authors":["Le Corff, S.","Fort, G.","Moulines, E."],"categories":null,"date":1377986400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1377986400,"objectID":"407c606bf3e0ad5e0c9a6122158fddea","permalink":"/publication/lecorff_fort_moulines_2013/","publishdate":"2013-09-01T00:00:00+02:00","relpermalink":"/publication/lecorff_fort_moulines_2013/","section":"publication","summary":"In this contribution, new online EM algorithms are proposed to perform inference in general hidden Markov models. These algorithms update the parameter at some deterministic times and use Sequential Monte Carlo methods to compute approximations of filtering distributions. In this paper, the performance of these algorithms are highlighted in the challenging framework of Simultaneous Localization and Mapping.","tags":[],"title":"New Online EM algorithms for general hidden Markov models. Application to the SLAM problem","type":"publication"},{"authors":["Dubarry, C.","Le Corff, S."],"categories":null,"date":1377986400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1377986400,"objectID":"ffcd5bc5e9f9c54712ebb94f8b2084ce","permalink":"/publication/dubarry_lecorff_2013/","publishdate":"2013-09-01T00:00:00+02:00","relpermalink":"/publication/dubarry_lecorff_2013/","section":"publication","summary":"The approximation of fixed-interval smoothing distributions is a key issue in inference for general state-space hidden Markov models (HMM). This contribution establishes non-asymptotic bounds for the Forward Filtering Backward Smoothing (FFBS) and the Forward Filtering Backward Simulation (FFBSi) estimators of fixed-interval smoothing functionals. We show that the rate of convergence of the Lq-mean errors of both methods depends on the number of observations T and the number of particles N only through the ratio T/N for additive functionals. In the case of the FFBS, this improves recent results providing bounds depending on T and the square root of N.","tags":[],"title":"Nonasymptotic deviation inequalities for smoothed additive functionals in nonlinear state-space models with applications to parameter estimation","type":"publication"},{"authors":["Dumont, T.","Le Corff, S"],"categories":null,"date":1377986400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1377986400,"objectID":"5daff1e4e9e8428968cb752579fcc605","permalink":"/publication/dumont_lecorff_2013/","publishdate":"2013-09-01T00:00:00+02:00","relpermalink":"/publication/dumont_lecorff_2013/","section":"publication","summary":"More detail can easily be written here using Markdown and $\\rm \\LaTeX$ math code.","tags":[],"title":"Online EM for indoor simultaneous localization and mapping","type":"publication"},{"authors":["Le Corff, S.","Fort, G."],"categories":null,"date":1377986400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1377986400,"objectID":"5e601b92e4a64b3bcaba61a81d8c604e","permalink":"/publication/lecorff_fort_2013/","publishdate":"2013-09-01T00:00:00+02:00","relpermalink":"/publication/lecorff_fort_2013/","section":"publication","summary":"The Expectation Maximization (EM) algorithm is a versatile tool for model parameter estimation in latent data models. When processing large data sets or data stream however, EM becomes intractable since it requires the whole data set to be available at each iteration of the algorithm. In this contribution, a new generic online EM algorithm for model parameter inference in general Hidden Markov Model is proposed. This new algorithm updates the parameter estimate after a block of observations is processed (online). The convergence of this new algorithm is established, and the rate of convergence is studied showing the impact of the block-size sequence. An averaging procedure is also proposed to improve the rate of convergence. Finally, practical illustrations are presented to highlight the performance of these algorithms in comparison to other online maximum likelihood procedures.","tags":[],"title":"Online Expectation Maximization based algorithms for inference in hidden Markov models","type":"publication"},{"authors":["Dubarry, C.","Le Corff, S"],"categories":null,"date":1314828000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1314828000,"objectID":"38c33cfa92faca9b433660f522a404c2","permalink":"/publication/dubarry_lecorff_2011/","publishdate":"2011-09-01T00:00:00+02:00","relpermalink":"/publication/dubarry_lecorff_2011/","section":"publication","summary":"More detail can easily be written here using Markdown and $\\rm \\LaTeX$ math code.","tags":[],"title":"Fast computation of smoothed additive functionals in general state-space models","type":"publication"},{"authors":["Le Corff, S.","Fort, G.","Moulines, E."],"categories":null,"date":1314828000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1314828000,"objectID":"1f2b1355a989d847ee44e8016e5c1bc8","permalink":"/publication/lecorff_fort_moulines_2011/","publishdate":"2011-09-01T00:00:00+02:00","relpermalink":"/publication/lecorff_fort_moulines_2011/","section":"publication","summary":"","tags":[],"title":"Online Expectation Maximization based algorithms for inference in hidden Markov models","type":"publication"}]